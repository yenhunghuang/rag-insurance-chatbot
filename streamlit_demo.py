#!/usr/bin/env python3
"""Streamlit Demo Interface

Simple Streamlit web interface for demonstrating the RAG insurance chatbot.
"""

import streamlit as st
import sys
import os
from pathlib import Path
import time
import json
from dotenv import load_dotenv

# Ensure .env is loaded before any imports
env_path = Path(__file__).parent / ".env"
load_dotenv(env_path)

# Add src to Python path
sys.path.insert(0, str(Path(__file__).parent / "src"))

from src.config import ConfigFactory, set_config, get_config
from src.generation import RAGSystem


# Page configuration
st.set_page_config(
    page_title="RAG æ—…éŠä¸ä¾¿éšªè«®è©¢ç³»çµ±",
    page_icon="ğŸ¨",
    layout="wide",
    initial_sidebar_state="expanded"
)

# Initialize system
@st.cache_resource
def initialize_rag_system():
    """Initialize RAG system with caching."""
    try:
        # Debug: Show environment variables
        st.write("ğŸ”§ **Debug Info - Environment Variables:**")
        st.write(f"- SIMILARITY_THRESHOLD: {os.getenv('SIMILARITY_THRESHOLD', 'NOT SET')}")
        st.write(f"- TOP_K: {os.getenv('TOP_K', 'NOT SET')}")
        st.write(f"- PINECONE_INDEX_NAME: {os.getenv('PINECONE_INDEX_NAME', 'NOT SET')}")
        
        config = ConfigFactory.load_from_env()
        set_config(config)
        
        # Debug: Show loaded configuration
        st.write("ğŸ”§ **Debug Info - Loaded Configuration:**")
        st.write(f"- retrieval.similarity_threshold: {config.retrieval.similarity_threshold}")
        st.write(f"- retrieval.top_k: {config.retrieval.top_k}")
        st.write(f"- pinecone.index_name: {config.pinecone.index_name}")
        
        rag_system = RAGSystem()
        
        # Initialize with insurance documents
        doc_path = "data/raw/æµ·å¤–æ—…è¡Œä¸ä¾¿éšªæ¢æ¬¾.txt"
        if os.path.exists(doc_path):
            result = rag_system.initialize_system(doc_path)
            if result["initialized"]:
                # Add configuration info to the result
                result["indexing_results"]["debug_config"] = {
                    "similarity_threshold": config.retrieval.similarity_threshold,
                    "top_k": config.retrieval.top_k,
                    "index_name": config.pinecone.index_name
                }
                return rag_system, result["indexing_results"]
            else:
                return None, {"error": "System initialization failed"}
        else:
            return None, {"error": f"Document not found: {doc_path}"}
            
    except Exception as e:
        return None, {"error": str(e)}


# Main interface
def main():
    """Main Streamlit interface."""
    
    # Header
    st.title("ğŸ¨ RAG æ—…éŠä¸ä¾¿éšªè«®è©¢ç³»çµ±")
    st.markdown("åŸºæ–¼æª¢ç´¢å¢å¼·ç”Ÿæˆ (RAG) æŠ€è¡“çš„æ™ºèƒ½ä¿éšªæ¢æ¬¾æŸ¥è©¢ç³»çµ±")
    
    # Initialize system
    with st.spinner("æ­£åœ¨åˆå§‹åŒ–ç³»çµ±..."):
        rag_system, init_info = initialize_rag_system()
    
    if rag_system is None:
        st.error(f"âŒ ç³»çµ±åˆå§‹åŒ–å¤±æ•—: {init_info.get('error', 'Unknown error')}")
        st.stop()
    
    # Sidebar with system info
    st.sidebar.header("ğŸ“Š ç³»çµ±è³‡è¨Š")
    
    # Add cache clear button
    if st.sidebar.button("ğŸ”„ æ¸…é™¤ç·©å­˜ä¸¦é‡æ–°è¼‰å…¥"):
        st.cache_resource.clear()
        st.rerun()
    
    if "error" not in init_info:
        st.sidebar.success("âœ… ç³»çµ±å·²å°±ç·’")
        st.sidebar.metric("æ–‡ä»¶ç‰‡æ®µ", init_info.get("total_chunks", 0))
        st.sidebar.metric("å‘é‡ç´¢å¼•", init_info.get("vectors_indexed", 0))
        st.sidebar.metric("åµŒå…¥ç¶­åº¦", init_info.get("embedding_dimension", 0))
        
        # Debug configuration info
        debug_config = init_info.get("debug_config", {})
        if debug_config:
            st.sidebar.header("ğŸ”§ é…ç½®è³‡è¨Š")
            st.sidebar.write(f"ç›¸ä¼¼åº¦é–¾å€¼: {debug_config.get('similarity_threshold', 'N/A')}")
            st.sidebar.write(f"æª¢ç´¢æ•¸é‡: {debug_config.get('top_k', 'N/A')}")
            st.sidebar.write(f"ç´¢å¼•åç¨±: {debug_config.get('index_name', 'N/A')}")
    
    # Sample queries
    st.sidebar.header("ğŸ’¡ ç¯„ä¾‹å•é¡Œ")
    sample_queries = [
        "ç­æ©Ÿå»¶èª¤è¶…éå¹¾å°æ™‚å¯ä»¥ç”³è«‹è³ å„Ÿï¼Ÿ",
        "è¡Œæéºå¤±å¾Œæ‡‰è©²å¦‚ä½•ç”³è«‹ç†è³ ï¼Ÿ", 
        "å“ªäº›æƒ…æ³ä¸‹æ—…éŠä¸ä¾¿éšªä¸æœƒç†è³ ï¼Ÿ",
        "æ—…ç¨‹å–æ¶ˆä¿éšªçš„æ‰¿ä¿ç¯„åœæœ‰å“ªäº›ï¼Ÿ",
        "è¡Œæå»¶èª¤é”åˆ°å¤šä¹…æ‰èƒ½ç”³è«‹ç†è³ ï¼Ÿ"
    ]
    
    selected_query = st.sidebar.selectbox(
        "é¸æ“‡ç¯„ä¾‹å•é¡Œï¼š",
        [""] + sample_queries
    )
    
    # Main query interface
    st.header("ğŸ’¬ å•é¡ŒæŸ¥è©¢")
    
    # Query input
    query_input = st.text_area(
        "è«‹è¼¸å…¥æ‚¨çš„ä¿éšªå•é¡Œï¼š",
        value=selected_query,
        height=100,
        placeholder="ä¾‹å¦‚ï¼šç­æ©Ÿå»¶èª¤è¶…éå¹¾å°æ™‚å¯ä»¥ç”³è«‹è³ å„Ÿï¼Ÿ"
    )
    
    # Query settings
    col1, col2, col3 = st.columns(3)
    
    with col1:
        top_k = st.slider("æª¢ç´¢æ–‡ä»¶æ•¸é‡", min_value=1, max_value=10, value=5)
    
    with col2:
        include_sources = st.checkbox("é¡¯ç¤ºä¾†æºå¼•ç”¨", value=True)
    
    with col3:
        show_confidence = st.checkbox("é¡¯ç¤ºä¿¡å¿ƒåˆ†æ•¸", value=True)
    
    # Process query
    if st.button("ğŸ” æŸ¥è©¢", type="primary", disabled=not query_input.strip()):
        with st.spinner("æ­£åœ¨è™•ç†æŸ¥è©¢..."):
            start_time = time.time()
            
            try:
                response = rag_system.query(
                    question=query_input.strip(),
                    top_k=top_k,
                    include_sources=include_sources
                )
                
                end_time = time.time()
                
                # Display response
                st.header("ğŸ“ å›ç­”")
                
                # Response metrics
                col1, col2, col3, col4 = st.columns(4)
                
                with col1:
                    st.metric("å›æ‡‰æ™‚é–“", f"{end_time - start_time:.2f}s")
                
                with col2:
                    if show_confidence:
                        st.metric("ä¿¡å¿ƒåˆ†æ•¸", f"{response.confidence:.2f}")
                
                with col3:
                    st.metric("åƒè€ƒä¾†æº", len(response.sources))
                
                with col4:
                    st.metric("å›ç­”é•·åº¦", f"{len(response.answer)}å­—")
                
                # Main answer
                st.markdown("### ğŸ“„ è©³ç´°å›ç­”")
                st.markdown(response.answer)
                
                # Source citations
                if include_sources and response.sources:
                    st.markdown("### ğŸ“š åƒè€ƒä¾†æº")
                    
                    for i, source in enumerate(response.sources, 1):
                        with st.expander(f"ä¾†æº {i}: {source.get('clause_number', 'N/A')} (ç›¸é—œåº¦: {source.get('relevance_score', 0):.2f})"):
                            st.markdown(f"**æ¢æ¬¾ç·¨è™Ÿ**: {source.get('clause_number', 'N/A')}")
                            st.markdown(f"**ä¾†æºæ–‡ä»¶**: {source.get('source_file', 'N/A')}")
                            st.markdown(f"**ç›¸é—œåº¦åˆ†æ•¸**: {source.get('relevance_score', 0):.3f}")
                            st.markdown(f"**å…§å®¹æ‘˜è¦**: {source.get('content_snippet', 'N/A')}")
                
                # Metadata
                if st.checkbox("é¡¯ç¤ºè©³ç´°è³‡è¨Š"):
                    st.markdown("### ğŸ”§ æŠ€è¡“è³‡è¨Š")
                    
                    metadata = response.metadata
                    
                    col1, col2 = st.columns(2)
                    
                    with col1:
                        st.json({
                            "æ¨¡å‹": metadata.get("model_used", "N/A"),
                            "ç”Ÿæˆæ™‚é–“": f"{metadata.get('generation_time', 0)}ç§’",
                            "å®ŒæˆåŸå› ": metadata.get("finish_reason", "N/A"),
                            "æ™‚é–“æˆ³": metadata.get("timestamp", "N/A")
                        })
                    
                    with col2:
                        usage = metadata.get("token_usage", {})
                        st.json({
                            "æç¤ºè©Token": usage.get("prompt_tokens", 0),
                            "å›ç­”Token": usage.get("completion_tokens", 0),
                            "ç¸½Token": usage.get("total_tokens", 0),
                            "å¹³å‡ç›¸é—œåº¦": f"{metadata.get('average_relevance_score', 0):.3f}"
                        })
                
            except Exception as e:
                st.error(f"âŒ æŸ¥è©¢è™•ç†å¤±æ•—: {str(e)}")
    
    # Footer
    st.markdown("---")
    st.markdown(
        """
        <div style='text-align: center'>
            <p>ğŸ¤– åŸºæ–¼ OpenAI GPT + Pinecone + Sentence Transformers æ§‹å»º</p>
            <p>ğŸ“š æ•¸æ“šä¾†æºï¼šæµ·å¤–æ—…è¡Œä¸ä¾¿éšªæ¢æ¬¾</p>
        </div>
        """, 
        unsafe_allow_html=True
    )


if __name__ == "__main__":
    main()