# Coding Standards & Best Practices

## ğŸ¯ Development Philosophy
**"å¯«çµ¦äººçœ‹çš„ä»£ç¢¼ï¼Œé †ä¾¿çµ¦æ©Ÿå™¨åŸ·è¡Œ"**
- ç¨‹å¼ç¢¼å¯è®€æ€§å„ªæ–¼è°æ˜æŠ€å·§
- æ˜ç¢ºå‹ééš±å«
- ç°¡å–®å‹éè¤‡é›œ  
- ä¸€è‡´æ€§å‹éå€‹äººåå¥½

---

## ğŸ“ Python Code Style

### PEP 8 Compliance + Project Extensions

#### Naming Conventions
```python
# âœ… è®Šæ•¸èˆ‡å‡½å¼: snake_case
user_query = "ä»€éº¼æƒ…æ³ä¸‹å¯ä»¥ç”³è«‹æ—…éŠå»¶èª¤è³ å„Ÿï¼Ÿ"
embedding_vector = generate_embedding(user_query)

def process_insurance_document(document: str) -> List[Chunk]:
    """è™•ç†ä¿éšªæ–‡æª”ä¸¦è¿”å›åˆ†å¡Šçµæœ"""
    pass

# âœ… é¡åˆ¥: PascalCase
class DocumentProcessor:
    """è² è²¬è™•ç†ä¿éšªæ¢æ¬¾æ–‡æª”çš„é¡åˆ¥"""
    pass

class RAGEngine:
    """æª¢ç´¢å¢å¼·ç”Ÿæˆå¼•æ“çš„ä¸»è¦å¯¦ä½œ"""
    pass

# âœ… å¸¸æ•¸: SCREAMING_SNAKE_CASE
MAX_CHUNK_SIZE = 256
OPENAI_MODEL_NAME = "gpt-3.5-turbo"
DEFAULT_SIMILARITY_THRESHOLD = 0.8

# âœ… ç§æœ‰æˆå“¡: å‰ç¶´å–®åº•ç·š
class VectorStore:
    def __init__(self):
        self._index = None
        self._documents = []
    
    def _build_index(self):
        """ç§æœ‰æ–¹æ³•ç”¨æ–¼å»ºæ§‹ç´¢å¼•"""
        pass

# âœ… æ¨¡çµ„ç´šç§æœ‰: å‰ç¶´å–®åº•ç·š
_DEFAULT_CONFIG = {...}

def _internal_helper_function():
    """æ¨¡çµ„å…§éƒ¨ä½¿ç”¨çš„è¼”åŠ©å‡½å¼"""
    pass
```

#### Line Length & Formatting
```python
# âœ… è¡Œé•·åº¦é™åˆ¶: 88å­—å…ƒ (Blackæ ¼å¼åŒ–å·¥å…·æ¨™æº–)
def search_relevant_clauses(
    query: str, 
    top_k: int = 5, 
    similarity_threshold: float = 0.8
) -> List[Document]:
    """æœå°‹ç›¸é—œçš„ä¿éšªæ¢æ¬¾"""
    pass

# âœ… é•·å­—ç¬¦ä¸²è™•ç†
error_message = (
    "æª¢ç´¢ç³»çµ±ç™¼ç”ŸéŒ¯èª¤ï¼šç„¡æ³•åœ¨æŒ‡å®šçš„ç›¸ä¼¼åº¦é–¾å€¼ä¸‹æ‰¾åˆ°ç›¸é—œæ¢æ¬¾ã€‚"
    "è«‹å˜—è©¦èª¿æ•´æŸ¥è©¢å…§å®¹æˆ–é™ä½ç›¸ä¼¼åº¦è¦æ±‚ã€‚"
)

# âœ… è¤‡é›œè¡¨é”å¼æ›è¡Œ
result = some_complex_function(
    parameter_one=value_one,
    parameter_two=value_two,
    parameter_three=very_long_value_that_exceeds_line_limit
)
```

### Type Annotations (å¼·åˆ¶è¦æ±‚)
```python
from typing import List, Dict, Optional, Union, Any
from dataclasses import dataclass

# âœ… å‡½å¼å‹åˆ¥æ¨™è¨»
def generate_embeddings(texts: List[str]) -> np.ndarray:
    """ç‚ºæ–‡æœ¬åˆ—è¡¨ç”ŸæˆåµŒå…¥å‘é‡"""
    pass

def search_documents(
    query: str, 
    top_k: int = 5
) -> List[Document]:
    """æœå°‹ç›¸é—œæ–‡æª”"""
    pass

# âœ… è¤‡é›œå‹åˆ¥å®šç¾©
QueryResult = Dict[str, Union[str, float, List[Document]]]

def process_query(query: str) -> QueryResult:
    """è™•ç†ç”¨æˆ¶æŸ¥è©¢ä¸¦è¿”å›çµæ§‹åŒ–çµæœ"""
    pass

# âœ… é¡åˆ¥å±¬æ€§å‹åˆ¥æ¨™è¨»  
@dataclass
class Document:
    content: str
    metadata: Dict[str, Any]
    embedding: Optional[np.ndarray] = None
    chunk_id: Optional[str] = None

# âœ… å¯é¸å‹åˆ¥è™•ç†
def load_config(config_path: Optional[str] = None) -> Config:
    """è¼‰å…¥é…ç½®ï¼Œå¦‚æœè·¯å¾‘ç‚ºç©ºå‰‡ä½¿ç”¨é è¨­"""
    if config_path is None:
        config_path = "default_config.yaml"
    # å¯¦ä½œé‚è¼¯
    pass
```

---

## ğŸ—ï¸ Architecture Patterns

### Dependency Injection Pattern
```python
# âœ… æŠ½è±¡ä»‹é¢å®šç¾©
from abc import ABC, abstractmethod

class RetrieverInterface(ABC):
    @abstractmethod
    def search(self, query: str, top_k: int) -> List[Document]:
        pass

class GeneratorInterface(ABC):
    @abstractmethod  
    def generate_response(self, context: str, query: str) -> str:
        pass

# âœ… ä¾è³´æ³¨å…¥å¯¦ä½œ
class RAGEngine:
    def __init__(
        self,
        retriever: RetrieverInterface,
        generator: GeneratorInterface,
        config: Config
    ):
        self.retriever = retriever
        self.generator = generator
        self.config = config
    
    def process_query(self, query: str) -> ChatbotResponse:
        # æ¥­å‹™é‚è¼¯ä¸ä¾è³´å…·é«”å¯¦ä½œ
        documents = self.retriever.search(query, self.config.top_k)
        context = self._build_context(documents)
        answer = self.generator.generate_response(context, query)
        return ChatbotResponse(answer=answer, sources=documents)

# âœ… Factory Pattern for DI
class ComponentFactory:
    @staticmethod
    def create_retriever(config: Config) -> RetrieverInterface:
        if config.retriever_type == "faiss":
            return FaissRetriever(config)
        elif config.retriever_type == "pinecone":
            return PineconeRetriever(config)
        else:
            raise ValueError(f"Unknown retriever type: {config.retriever_type}")
```

### Error Handling Strategy
```python
# âœ… è‡ªå®šç¾©ä¾‹å¤–é¡åˆ¥å±¤æ¬¡çµæ§‹
class RAGSystemError(Exception):
    """RAGç³»çµ±åŸºç¤ä¾‹å¤–é¡åˆ¥"""
    pass

class RetrievalError(RAGSystemError):
    """æª¢ç´¢ç›¸é—œéŒ¯èª¤"""
    pass

class GenerationError(RAGSystemError):
    """ç”Ÿæˆç›¸é—œéŒ¯èª¤"""
    pass

class ConfigurationError(RAGSystemError):
    """é…ç½®ç›¸é—œéŒ¯èª¤"""
    pass

# âœ… éŒ¯èª¤è™•ç†æœ€ä½³å¯¦è¸
import logging

logger = logging.getLogger(__name__)

def search_documents(query: str) -> List[Document]:
    try:
        # æª¢ç´¢é‚è¼¯
        results = perform_vector_search(query)
        if not results:
            logger.warning(f"No documents found for query: {query}")
            return []
        return results
        
    except ConnectionError as e:
        logger.error(f"Vector database connection failed: {e}")
        raise RetrievalError(f"æª¢ç´¢æœå‹™æš«æ™‚ç„¡æ³•ä½¿ç”¨: {e}") from e
        
    except ValueError as e:
        logger.error(f"Invalid query format: {e}")
        raise RetrievalError(f"æŸ¥è©¢æ ¼å¼éŒ¯èª¤: {e}") from e
        
    except Exception as e:
        logger.exception(f"Unexpected error in document search: {e}")
        raise RAGSystemError(f"ç³»çµ±ç™¼ç”Ÿæœªé æœŸéŒ¯èª¤") from e

# âœ… Context Manager for Resource Management  
from contextlib import contextmanager

@contextmanager
def vector_store_connection(config: Config):
    """å‘é‡è³‡æ–™åº«é€£ç·šçš„ä¸Šä¸‹æ–‡ç®¡ç†å™¨"""
    store = None
    try:
        store = VectorStore(config)
        store.connect()
        yield store
    except Exception as e:
        logger.error(f"Vector store connection error: {e}")
        raise
    finally:
        if store:
            store.disconnect()
```

### Configuration Management
```python
# âœ… çµæ§‹åŒ–é…ç½®é¡åˆ¥
from dataclasses import dataclass, field
from typing import List
import os

@dataclass
class EmbeddingConfig:
    model_name: str = "paraphrase-multilingual-MiniLM-L12-v2"
    batch_size: int = 32
    max_length: int = 512

@dataclass  
class RetrievalConfig:
    top_k: int = 5
    similarity_threshold: float = 0.8
    index_type: str = "faiss"

@dataclass
class GenerationConfig:
    model_name: str = "gpt-3.5-turbo"
    temperature: float = 0.1
    max_tokens: int = 500
    
@dataclass
class AppConfig:
    # ç’°å¢ƒè®Šæ•¸æ•´åˆ
    openai_api_key: str = field(default_factory=lambda: os.getenv("OPENAI_API_KEY"))
    log_level: str = field(default_factory=lambda: os.getenv("LOG_LEVEL", "INFO"))
    
    # å­é…ç½®çµ„åˆ
    embedding: EmbeddingConfig = field(default_factory=EmbeddingConfig)
    retrieval: RetrievalConfig = field(default_factory=RetrievalConfig)  
    generation: GenerationConfig = field(default_factory=GenerationConfig)
    
    # é©—è­‰æ–¹æ³•
    def __post_init__(self):
        if not self.openai_api_key:
            raise ConfigurationError("OPENAI_API_KEY environment variable is required")
        
        if self.retrieval.top_k <= 0:
            raise ConfigurationError("retrieval.top_k must be positive")

# âœ… é…ç½®è¼‰å…¥å·¥å» 
class ConfigFactory:
    @staticmethod
    def load_from_env() -> AppConfig:
        """å¾ç’°å¢ƒè®Šæ•¸è¼‰å…¥é…ç½®"""
        return AppConfig()
    
    @staticmethod
    def load_from_file(config_path: str) -> AppConfig:
        """å¾YAMLæª”æ¡ˆè¼‰å…¥é…ç½®"""
        import yaml
        with open(config_path, 'r') as f:
            data = yaml.safe_load(f)
        return AppConfig(**data)
```

---

## ğŸ§ª Testing Standards

### Test Organization
```python
# tests/unit/test_document_processor.py
import pytest
from unittest.mock import Mock, patch
from src.processing import DocumentProcessor
from src.models import Document

class TestDocumentProcessor:
    """DocumentProcessorçš„å–®å…ƒæ¸¬è©¦"""
    
    def setup_method(self):
        """æ¯å€‹æ¸¬è©¦æ–¹æ³•åŸ·è¡Œå‰çš„è¨­ç½®"""
        self.processor = DocumentProcessor()
        self.sample_text = "ç¬¬3.1æ¢ æ—…ç¨‹å»¶èª¤ä¿éšœï¼šè¢«ä¿éšªäººä¹‹åŸå®šæ­ä¹˜ç­æ©Ÿ..."
    
    def test_chunk_document_basic(self):
        """æ¸¬è©¦åŸºæœ¬æ–‡æª”åˆ†å¡ŠåŠŸèƒ½"""
        # Arrange
        expected_chunks = 2
        
        # Act  
        result = self.processor.chunk_document(self.sample_text)
        
        # Assert
        assert len(result) == expected_chunks
        assert all(isinstance(chunk, Document) for chunk in result)
        assert all(chunk.content for chunk in result)
    
    def test_chunk_document_empty_input(self):
        """æ¸¬è©¦ç©ºè¼¸å…¥çš„é‚Šç•Œæƒ…æ³"""
        # Act & Assert
        with pytest.raises(ValueError, match="æ–‡æª”å…§å®¹ä¸èƒ½ç‚ºç©º"):
            self.processor.chunk_document("")
    
    @patch('src.processing.document_processor.extract_metadata')
    def test_chunk_with_metadata(self, mock_extract):
        """æ¸¬è©¦å¸¶æœ‰å…ƒæ•¸æ“šçš„åˆ†å¡Š"""
        # Arrange
        mock_extract.return_value = {"article": "3.1", "type": "coverage"}
        
        # Act
        result = self.processor.chunk_document(self.sample_text)
        
        # Assert  
        mock_extract.assert_called_once()
        assert result[0].metadata["article"] == "3.1"

# âœ… Integration Test Example
# tests/integration/test_rag_pipeline.py
class TestRAGPipeline:
    """RAGç³»çµ±æ•´åˆæ¸¬è©¦"""
    
    @pytest.fixture
    def rag_system(self):
        """RAGç³»çµ±æ¸¬è©¦è£ç½®"""
        config = AppConfig()
        retriever = FaissRetriever(config)
        generator = OpenAIGenerator(config)
        return RAGEngine(retriever, generator, config)
    
    def test_end_to_end_query(self, rag_system):
        """ç«¯åˆ°ç«¯æŸ¥è©¢æ¸¬è©¦"""
        # Arrange
        test_query = "ä»€éº¼æƒ…æ³ä¸‹å¯ä»¥ç”³è«‹æ—…éŠå»¶èª¤è³ å„Ÿï¼Ÿ"
        
        # Act
        response = rag_system.process_query(test_query)
        
        # Assert
        assert response.answer
        assert len(response.sources) > 0
        assert response.confidence > 0.5
        assert "å»¶èª¤" in response.answer
```

### Test Data Management
```python
# tests/conftest.py - å…±ç”¨æ¸¬è©¦è¨­å‚™
import pytest
from pathlib import Path

@pytest.fixture(scope="session")
def test_data_dir():
    """æ¸¬è©¦æ•¸æ“šç›®éŒ„"""
    return Path(__file__).parent / "data"

@pytest.fixture(scope="session") 
def sample_insurance_clauses(test_data_dir):
    """æ¨£æœ¬ä¿éšªæ¢æ¬¾"""
    with open(test_data_dir / "sample_clauses.json") as f:
        return json.load(f)

@pytest.fixture(scope="function")
def mock_openai_response():
    """æ¨¡æ“¬OpenAI APIå›æ‡‰"""
    return {
        "choices": [{
            "message": {
                "content": "æ ¹æ“šç¬¬3.1æ¢è¦å®šï¼Œç•¶ç­æ©Ÿå»¶èª¤é”4å°æ™‚ä»¥ä¸Šæ™‚..."
            }
        }]
    }

# âœ… Test Categories
"""
æ¸¬è©¦åˆ†é¡æ¨™è¨˜:
@pytest.mark.unit       - å–®å…ƒæ¸¬è©¦  
@pytest.mark.integration - æ•´åˆæ¸¬è©¦
@pytest.mark.e2e        - ç«¯åˆ°ç«¯æ¸¬è©¦
@pytest.mark.slow       - æ…¢é€Ÿæ¸¬è©¦ (éœ€è¦å¤–éƒ¨API)
@pytest.mark.gpu        - éœ€è¦GPUçš„æ¸¬è©¦
"""

@pytest.mark.slow
@pytest.mark.integration
def test_openai_api_integration():
    """æ¸¬è©¦OpenAI APIæ•´åˆ (éœ€è¦å¯¦éš›APIèª¿ç”¨)"""
    pass
```

---

## ğŸ“š Documentation Standards

### Docstring Conventions (Google Style)
```python
def search_insurance_clauses(
    query: str,
    clause_types: List[str] = None,
    similarity_threshold: float = 0.8,
    max_results: int = 5
) -> List[Document]:
    """æœå°‹ç›¸é—œçš„ä¿éšªæ¢æ¬¾ã€‚
    
    æ ¹æ“šç”¨æˆ¶æŸ¥è©¢åœ¨ä¿éšªæ¢æ¬¾è³‡æ–™åº«ä¸­æœå°‹ç›¸é—œå…§å®¹ï¼Œæ”¯æ´æ¢æ¬¾é¡å‹éæ¿¾
    å’Œç›¸ä¼¼åº¦é–¾å€¼è¨­å®šã€‚
    
    Args:
        query: ç”¨æˆ¶æŸ¥è©¢æ–‡æœ¬ï¼Œä¾‹å¦‚"ä»€éº¼æƒ…æ³å¯ä»¥ç”³è«‹å»¶èª¤è³ å„Ÿï¼Ÿ"
        clause_types: é™åˆ¶æœå°‹çš„æ¢æ¬¾é¡å‹åˆ—è¡¨ï¼Œå¯é¸å€¼åŒ…æ‹¬:
            - "coverage": ä¿éšœæ¢æ¬¾
            - "exclusion": å…è²¬æ¢æ¬¾  
            - "procedure": ç”³è«‹ç¨‹åº
            é è¨­ç‚ºNoneè¡¨ç¤ºæœå°‹æ‰€æœ‰é¡å‹ã€‚
        similarity_threshold: ç›¸ä¼¼åº¦æœ€å°é–¾å€¼ï¼Œç¯„åœ0.0-1.0ï¼Œ
            é è¨­0.8è¡¨ç¤ºåªè¿”å›é«˜ç›¸é—œæ€§çµæœã€‚
        max_results: æœ€å¤§è¿”å›çµæœæ•¸é‡ï¼Œé è¨­5ã€‚
    
    Returns:
        æŒ‰ç›¸é—œæ€§æ’åºçš„Documentåˆ—è¡¨ï¼Œæ¯å€‹DocumentåŒ…å«:
        - content: æ¢æ¬¾å…§å®¹æ–‡æœ¬
        - metadata: åŒ…å«æ¢æ¬¾ç·¨è™Ÿã€é¡å‹ç­‰è³‡è¨Š
        - similarity_score: èˆ‡æŸ¥è©¢çš„ç›¸ä¼¼åº¦åˆ†æ•¸
    
    Raises:
        RetrievalError: ç•¶æª¢ç´¢ç³»çµ±ç„¡æ³•é€£ç·šæˆ–æŸ¥è©¢æ ¼å¼éŒ¯èª¤æ™‚ã€‚
        ValueError: ç•¶åƒæ•¸å€¼è¶…å‡ºæœ‰æ•ˆç¯„åœæ™‚ã€‚
    
    Example:
        >>> searcher = ClauseSearcher()
        >>> results = searcher.search_insurance_clauses(
        ...     "è¡Œæéºå¤±ç†è³ ",
        ...     clause_types=["coverage", "procedure"],
        ...     max_results=3
        ... )
        >>> print(f"æ‰¾åˆ° {len(results)} å€‹ç›¸é—œæ¢æ¬¾")
        æ‰¾åˆ° 3 å€‹ç›¸é—œæ¢æ¬¾
    
    Note:
        æ­¤å‡½å¼æœƒè¨˜éŒ„æŸ¥è©¢çµ±è¨ˆè³‡è¨Šç”¨æ–¼ç³»çµ±ç›£æ§å’Œæ€§èƒ½åˆ†æã€‚
        å°æ–¼ç›¸åŒæŸ¥è©¢ï¼Œçµæœæœƒè¢«ç·©å­˜30åˆ†é˜ä»¥æå‡å›æ‡‰é€Ÿåº¦ã€‚
    """
    # å¯¦ä½œé‚è¼¯...
    pass

# âœ… é¡åˆ¥æ–‡æª”æ¨™æº–
class RAGEngine:
    """æª¢ç´¢å¢å¼·ç”Ÿæˆ(RAG)å¼•æ“çš„æ ¸å¿ƒå¯¦ä½œã€‚
    
    RAGEngineæ•´åˆäº†æ–‡æª”æª¢ç´¢å’Œèªè¨€ç”ŸæˆåŠŸèƒ½ï¼Œç‚ºä¿éšªæ¢æ¬¾æŸ¥è©¢
    æä¾›æ™ºèƒ½å•ç­”æœå‹™ã€‚ç³»çµ±æ¡ç”¨èªç¾©æª¢ç´¢é…åˆGPTæ¨¡å‹ç”Ÿæˆï¼Œ
    ç¢ºä¿å›ç­”æº–ç¢ºæ€§å’Œå¯è¿½æº¯æ€§ã€‚
    
    Attributes:
        retriever: æ–‡æª”æª¢ç´¢å™¨å¯¦ä¾‹ï¼Œè² è²¬æ‰¾å°‹ç›¸é—œæ¢æ¬¾ã€‚
        generator: å›ç­”ç”Ÿæˆå™¨å¯¦ä¾‹ï¼Œè² è²¬åˆæˆè‡ªç„¶èªè¨€å›ç­”ã€‚
        config: ç³»çµ±é…ç½®ç‰©ä»¶ï¼ŒåŒ…å«æ¨¡å‹åƒæ•¸å’Œæ¥­å‹™è¦å‰‡ã€‚
    
    Example:
        >>> config = AppConfig()
        >>> retriever = FaissRetriever(config)
        >>> generator = OpenAIGenerator(config)
        >>> rag = RAGEngine(retriever, generator, config)
        >>> 
        >>> response = rag.process_query("ä»€éº¼æƒ…æ³å¯ä»¥ç”³è«‹å»¶èª¤è³ å„Ÿï¼Ÿ")
        >>> print(response.answer)
        æ ¹æ“šç¬¬3.1æ¢è¦å®šï¼Œç•¶ç­æ©Ÿå› å¤©å€™å› ç´ å»¶èª¤é”4å°æ™‚ä»¥ä¸Šæ™‚...
    """
    
    def __init__(self, retriever: RetrieverInterface, ...):
        """åˆå§‹åŒ–RAGå¼•æ“ã€‚
        
        Args:
            retriever: å¯¦ä½œRetrieverInterfaceçš„æª¢ç´¢å™¨
            generator: å¯¦ä½œGeneratorInterfaceçš„ç”Ÿæˆå™¨  
            config: ç³»çµ±é…ç½®ç‰©ä»¶
        """
        pass
```

### Code Comments Guidelines
```python
# âœ… é©ç•¶çš„è¨»è§£ä½¿ç”¨
class DocumentProcessor:
    def chunk_document(self, text: str) -> List[Document]:
        # Step 1: æ¸…ç†æ–‡æœ¬æ ¼å¼å’Œç‰¹æ®Šå­—ç¬¦
        cleaned_text = self._clean_text(text)
        
        # Step 2: æŒ‰èªç¾©é‚Šç•Œåˆ†å‰²æ¢æ¬¾
        # ä¿éšªæ¢æ¬¾é€šå¸¸ä»¥"ç¬¬Xæ¢"æˆ–"ç¬¬X.Yæ¢"é–‹å§‹
        clause_boundaries = self._find_clause_boundaries(cleaned_text)
        
        chunks = []
        for i, boundary in enumerate(clause_boundaries):
            # Step 3: æå–æ¯å€‹æ¢æ¬¾çš„å…§å®¹å’Œç·¨è™Ÿ
            clause_content = self._extract_clause_content(
                cleaned_text, 
                boundary, 
                clause_boundaries[i+1] if i+1 < len(clause_boundaries) else None
            )
            
            # Step 4: ç‚ºæ¯å€‹chunkç”Ÿæˆçµæ§‹åŒ–å…ƒæ•¸æ“š
            metadata = self._extract_metadata(clause_content)
            
            chunk = Document(
                content=clause_content,
                metadata=metadata,
                chunk_id=f"clause_{i}"
            )
            chunks.append(chunk)
        
        return chunks

# âŒ é¿å…çš„è¨»è§£æ¨¡å¼
def add_numbers(a, b):
    # å°‡ a å’Œ b ç›¸åŠ     <- å†—é¤˜è¨»è§£
    return a + b        

x = x + 1  # å°‡xå¢åŠ 1      <- é¡¯è€Œæ˜“è¦‹çš„è¨»è§£

# TODO: ä¿®å¾©é€™å€‹bug     <- æ¨¡ç³Šçš„TODO
# HACK: æš«æ™‚çš„è§£æ±ºæ–¹æ¡ˆ  <- æ²’æœ‰èªªæ˜åŸå› å’Œæ›¿ä»£æ–¹æ¡ˆ

# âœ… æœ‰åƒ¹å€¼çš„è¨»è§£
def calculate_similarity_threshold(user_expertise_level: str) -> float:
    """æ ¹æ“šç”¨æˆ¶å°ˆæ¥­ç¨‹åº¦å‹•æ…‹èª¿æ•´ç›¸ä¼¼åº¦é–¾å€¼"""
    # ä¿éšªå°ˆæ¥­äººå£«å¯ä»¥æ¥å—æ›´ä½ç›¸ä¼¼åº¦çš„çµæœï¼Œ
    # å› ç‚ºä»–å€‘å…·å‚™è¶³å¤ çŸ¥è­˜åˆ¤æ–·ç›¸é—œæ€§
    if user_expertise_level == "expert":
        return 0.6
    # ä¸€èˆ¬æ¶ˆè²»è€…éœ€è¦æ›´é«˜ç›¸ä¼¼åº¦ç¢ºä¿ç­”æ¡ˆæº–ç¢ºæ€§
    elif user_expertise_level == "consumer":  
        return 0.85
    else:
        return 0.8  # é è¨­ä¸­ç­‰é–¾å€¼

    # FIXME: éœ€è¦å„ªåŒ–å¤§å‹æ–‡æª”çš„åˆ†å¡Šç­–ç•¥
    # ç•¶å‰å¯¦ä½œåœ¨è™•ç†>1MBæ–‡æª”æ™‚æœƒæœ‰è¨˜æ†¶é«”å•é¡Œ
    # æ›¿ä»£æ–¹æ¡ˆ: è€ƒæ…®ä½¿ç”¨streamingæˆ–lazy loading
    # GitHub Issue: #123
```

---

## ğŸ” Code Review Checklist

### Pre-Review Requirements
```
âœ… è‡ªæˆ‘æª¢æŸ¥æ¸…å–®:
- [ ] æ‰€æœ‰å‡½å¼éƒ½æœ‰å‹åˆ¥æ¨™è¨»å’Œdocstring
- [ ] å–®å…ƒæ¸¬è©¦è¦†è“‹ç‡ â‰¥ 80%
- [ ] Blackæ ¼å¼åŒ–å·²åŸ·è¡Œ  
- [ ] Flake8æª¢æŸ¥é€šé
- [ ] æ²’æœ‰æ˜é¡¯çš„ä»£ç¢¼é‡è¤‡
- [ ] éŒ¯èª¤è™•ç†é©ç•¶ä¸”å…·é«”
- [ ] æ•æ„Ÿè³‡è¨Šå·²ç§»é™¤ (API keys, passwords)
- [ ] Importé †åºç¬¦åˆè¦ç¯„
```

### Review Focus Areas
```python
# ğŸ” å¯©æŸ¥é‡é» 1: éŒ¯èª¤è™•ç†
def risky_function():
    try:
        result = external_api_call()
        return result
    except Exception:  # âŒ éæ–¼å¯¬æ³›çš„ä¾‹å¤–æ•æ‰
        pass           # âŒ éœé»˜å¿½ç•¥éŒ¯èª¤
        
# âœ… æ”¹é€²ç‰ˆæœ¬        
def improved_function():
    try:
        result = external_api_call()
        return result
    except requests.ConnectionError as e:
        logger.error(f"API connection failed: {e}")
        raise RetrievalError("æª¢ç´¢æœå‹™æš«æ™‚ç„¡æ³•ä½¿ç”¨") from e
    except requests.Timeout as e:
        logger.warning(f"API timeout: {e}")
        raise RetrievalError("æª¢ç´¢æœå‹™å›æ‡‰è¶…æ™‚") from e

# ğŸ” å¯©æŸ¥é‡é» 2: è³‡æºç®¡ç†
class VectorStore:
    def __init__(self):
        self.connection = None
    
    def connect(self):
        self.connection = create_connection()
    
    # âŒ æ²’æœ‰æ˜ç¢ºçš„è³‡æºæ¸…ç†
    def __del__(self):  # âŒ ä¸å¯é çš„è³‡æºæ¸…ç†æ–¹å¼
        if self.connection:
            self.connection.close()

# âœ… æ”¹é€²ç‰ˆæœ¬
class VectorStore:
    def __enter__(self):
        self.connection = create_connection()
        return self
        
    def __exit__(self, exc_type, exc_val, exc_tb):
        if self.connection:
            self.connection.close()
    
    # æˆ–è€…æä¾›æ˜ç¢ºçš„æ¸…ç†æ–¹æ³•
    def disconnect(self):
        if self.connection:
            self.connection.close()
            self.connection = None

# ğŸ” å¯©æŸ¥é‡é» 3: æ€§èƒ½è€ƒæ…®
def process_documents(documents):
    results = []
    for doc in documents:  # âŒ é †åºè™•ç†ï¼Œæ•ˆç‡ä½
        embedding = generate_embedding(doc.content)  # âŒ é‡è¤‡çš„æ¨¡å‹è¼‰å…¥
        results.append(embedding)
    return results

# âœ… æ”¹é€²ç‰ˆæœ¬
def process_documents(documents):
    # æ‰¹é‡è™•ç†æå‡æ•ˆç‡
    contents = [doc.content for doc in documents]
    embeddings = generate_embeddings_batch(contents)
    return embeddings
```

---

## ğŸš€ Performance Guidelines

### Memory Management
```python
# âœ… è¨˜æ†¶é«”æ•ˆç‡çš„è¨­è¨ˆ
class EmbeddingCache:
    def __init__(self, max_size: int = 1000):
        from collections import OrderedDict
        self._cache = OrderedDict()
        self._max_size = max_size
    
    def get_embedding(self, text: str) -> Optional[np.ndarray]:
        if text in self._cache:
            # LRU: ç§»å‹•åˆ°æœ€å¾Œè¡¨ç¤ºæœ€è¿‘ä½¿ç”¨
            self._cache.move_to_end(text)
            return self._cache[text]
        return None
    
    def set_embedding(self, text: str, embedding: np.ndarray):
        self._cache[text] = embedding
        self._cache.move_to_end(text)
        
        # ç¶­æŒç·©å­˜å¤§å°é™åˆ¶
        if len(self._cache) > self._max_size:
            self._cache.popitem(last=False)

# âœ… Generatorç”¨æ–¼å¤§å‹æ•¸æ“šè™•ç†
def load_documents(file_path: str) -> Iterator[Document]:
    """ä½¿ç”¨generatoré¿å…ä¸€æ¬¡æ€§è¼‰å…¥å¤§é‡æ–‡æª”åˆ°è¨˜æ†¶é«”"""
    with open(file_path, 'r') as f:
        for line in f:
            data = json.loads(line)
            yield Document(
                content=data['content'],
                metadata=data['metadata']
            )

# âœ… é©ç•¶çš„è³‡æ–™çµæ§‹é¸æ“‡
class DocumentIndex:
    def __init__(self):
        # ä½¿ç”¨seté€²è¡Œå¿«é€Ÿæˆå“¡æª¢æŸ¥
        self._processed_ids = set()
        # ä½¿ç”¨dicté€²è¡Œå¿«é€ŸIDæŸ¥æ‰¾
        self._id_to_document = {}
        # ä½¿ç”¨dequeé€²è¡Œé«˜æ•ˆä½‡åˆ—æ“ä½œ
        from collections import deque
        self._processing_queue = deque()
```

### Async Programming Standards  
```python
import asyncio
import aiohttp
from typing import List

# âœ… ç•°æ­¥APIå‘¼å«
class AsyncLLMClient:
    def __init__(self):
        self.session = None
    
    async def __aenter__(self):
        self.session = aiohttp.ClientSession()
        return self
    
    async def __aexit__(self, exc_type, exc_val, exc_tb):
        await self.session.close()
    
    async def generate_response(self, prompt: str) -> str:
        """ç•°æ­¥ç”Ÿæˆå›ç­”"""
        async with self.session.post(
            'https://api.openai.com/v1/chat/completions',
            json={
                'model': 'gpt-3.5-turbo',
                'messages': [{'role': 'user', 'content': prompt}]
            }
        ) as response:
            data = await response.json()
            return data['choices'][0]['message']['content']

# âœ… æ‰¹é‡ç•°æ­¥è™•ç†
async def process_multiple_queries(queries: List[str]) -> List[str]:
    """ä¸¦è¡Œè™•ç†å¤šå€‹æŸ¥è©¢ä»¥æå‡throughput"""
    async with AsyncLLMClient() as client:
        tasks = [
            client.generate_response(query) 
            for query in queries
        ]
        results = await asyncio.gather(*tasks)
        return results
```

---

_This coding standards document ensures consistent, maintainable, and performant code across the RAG system implementation._